{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Copy model simulation and analysis workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run 20190717_workflow.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  get_hist\n",
      "  simulate\n",
      "  analyze\n",
      "  default\n",
      "  get_data_hist\n",
      "\n",
      "Global Workflow Options:\n",
      "  --cnv-type deletion\n",
      "  --cwd /home/min/GIT/github/cnv-gene-mapping/data (as path)\n",
      "  --genotype-file  path(f\"{cwd:a}/{cnv_type}.X.gz\")\n",
      "\n",
      "  --phenotype-file  path(f\"{cwd:a}/{cnv_type}.y\") # real CNV data phenotype\n",
      "\n",
      "\n",
      "Sections\n",
      "  get_hist_1, simulate_1, analyze_1:\n",
      "    Workflow Options:\n",
      "      --n-gene-in-block 1 (as int)\n",
      "                        For simulation: get real deletion/duplication CNV data\n",
      "                        and its block n_gene_in_block: get_hist: 1, simulate:\n",
      "                        20~50, analyze: 1\n",
      "  simulate_2:\n",
      "  simulate_3:\n",
      "    Workflow Options:\n",
      "      --sample-size 100000 (as int)\n",
      "      --n-batch 200 (as int)\n",
      "  simulate_4:\n",
      "  simulate_5:\n",
      "    Workflow Options:\n",
      "      --shape 3.0 (as float)\n",
      "                        shape = 3; scale = 1 for gamma shape = 2.191013; scale =\n",
      "                        0.2682398 for normal\n",
      "      --scale 1.0 (as float)\n",
      "      --beta-method normal\n",
      "                        'gamma' or 'normal'\n",
      "      --penetrance 0.05 (as float)\n",
      "      --seed 999999 (as int)\n",
      "      --ctrl-case-ratio 1.0 (as float)\n",
      "      --pi0 0.95 (as float)\n",
      "  analyze_2:\n",
      "    Workflow Options:\n",
      "      --L 1 (as int)\n",
      "      --pve 0.005 (as float)\n",
      "      --method optim\n",
      "      --real TRUE\n",
      "      --simu-pheno VAL (required)\n",
      "  get_hist_2:\n",
      "  default_1, get_data_hist_1:\n",
      "    Workflow Options:\n",
      "      --n-gene-in-block 20 (as int)\n",
      "  default_2:\n",
      "    Workflow Options:\n",
      "      --sample-size 100000 (as int)\n",
      "      --n-batch 200 (as int)\n",
      "  default_3:\n",
      "  default_4:\n",
      "    Workflow Options:\n",
      "      --shape 3 (as int)\n",
      "                        For shape = 3; scale = 1 for gamma shape = 2.191013;\n",
      "                        scale = 0.2682398 for normal\n",
      "      --scale 1 (as int)\n",
      "      --beta-method normal\n",
      "                        'gamma' or 'normal'\n",
      "      --penetrance 0.05 (as float)\n",
      "      --seed 999999 (as int)\n",
      "      --ctrl-case-ratio 1.0 (as float)\n",
      "      --pi0 0.95 (as float)\n",
      "  default_5, get_data_hist_2:\n",
      "  default_6:\n",
      "  default_7:\n",
      "    Workflow Options:\n",
      "      --L 10 (as int)\n",
      "      --pve 0.005 (as float)\n",
      "      --method optim\n"
     ]
    }
   ],
   "source": [
    "!sos run 20190717_workflow.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Run this workflow\n",
    "### Simulation:\n",
    "```\n",
    "sos run dsc/20190717_workflow.ipynb simulate:1-5 --n_gene_in_block 30 --shape 1 --scale 0.5 -s build\n",
    "```\n",
    "### Get histogram\n",
    "- For simulation\n",
    "```\n",
    "sos run dsc/20190717_workflow.ipynb get_hist:1-2 --genotype_file /home/min/GIT/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.X.gz \\\n",
    "--n_gene_in_block 1 -s build\n",
    "```\n",
    "- For real data\n",
    "```\n",
    "sos run dsc/20190717_workflow.ipynb get_hist:1-2 --n_gene_in_block 1 -s build\n",
    "```\n",
    "\n",
    "### Analyze\n",
    "```\n",
    "sos run dsc/20190717_workflow.ipynb analyze:1-2 --genotype_file /home/min/GIT/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.X.gz \\\n",
    "--phenotype_file /home/min/GIT/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.y --n_gene_in_block 1 -s build\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "parameter: cnv_type = \"deletion\"\n",
    "parameter: cwd = path(\"~/GIT/github/cnv-gene-mapping/data\")\n",
    "parameter: genotype_file = path(f\"{cwd:a}/{cnv_type}.X.gz\")\n",
    "parameter: phenotype_file = path(f\"{cwd:a}/{cnv_type}.y\") # real CNV data phenotype\n",
    "def fmtP(x):\n",
    "    return str(x).replace(\".\", \"p\").replace(' ', '_').replace('\"', \"\").replace(\"'\", \"\").replace(\"-\", '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[get_hist_1, simulate_1, susie_1, varbvs_1]\n",
    "# For simulation: get real deletion/duplication CNV data and its block\n",
    "# n_gene_in_block: get_hist: 1, simulate: 20~50, analyze: 1\n",
    "parameter: n_gene_in_block = 1\n",
    "input: genotype_file\n",
    "output: f\"{_input:nn}.genes.block{n_gene_in_block}.gz\", f\"{_input:nn}.block{n_gene_in_block}.start.end.csv\"\n",
    "python: expand = '${ }'\n",
    "    import pandas as pd\n",
    "    from operator import itemgetter\n",
    "    from itertools import *\n",
    "    data = pd.read_csv(${_input:r}, compression = \"gzip\", sep = \"\\t\", header = None)\n",
    "    data_clean = data.loc[:, (data != 0).any(axis = 0)]\n",
    "    data_clean.to_csv(${_output[0]:r}, compression = \"gzip\", sep = \"\\t\", header = True, index = False)\n",
    "    indices = list(data_clean.columns)\n",
    "    groups = list()\n",
    "    for k, g in groupby(enumerate(indices), lambda x: x[0]-x[1]):\n",
    "        groups.extend(list(map(itemgetter(1), g)))\n",
    "    if groups[0] != list(data.columns)[0]:\n",
    "        groups = [list(data.columns)[0]] + groups\n",
    "    if groups[-1] != list(data.columns)[-1]:\n",
    "        groups = groups + [list(data.columns)[-1]]\n",
    "    bound = list()\n",
    "    i = 0; j = 1; n_0 = len(groups)\n",
    "    while (j < n_0):\n",
    "        if groups[j] - groups[i] >= ${n_gene_in_block} and groups[j] - groups[j-1] > 1:\n",
    "            bound.append([groups[i], groups[j-1]])\n",
    "            i = j\n",
    "        j += 1\n",
    "    bound = [item for item in bound if item[1] != 0]\n",
    "    pd.DataFrame(bound, columns = [\"block_start\", \"block_end\"]).to_csv(${_output[1]:r}, sep = \"\\t\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[simulate_2]\n",
    "output: f\"{_input[0]:n}.for_simu.gz\"\n",
    "python: expand = '${ }'\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(${genotype_file:r}, compression = \"gzip\", header = None, sep = \"\\t\")\n",
    "    bound = pd.read_csv(${_input[1]:r}, header = 0, sep = \"\\t\")\n",
    "    bound2 = [[item[0], item[1]] if item[0] == bound.values[-1][0] else [item[0], bound.values[j+1][0]-1] for j, item in enumerate(bound.values)]\n",
    "    fill = list()\n",
    "    for l in range(data.shape[0]):\n",
    "        fill.append([data.loc[l, k[0]:k[1]].tolist() for k in bound2])\n",
    "    res = pd.DataFrame(fill)\n",
    "    res.to_csv(${_output:r}, sep = \"\\t\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[simulate_3]\n",
    "parameter: sample_size = 100000 # sample size: default 100000, test: 1000\n",
    "parameter: n_batch = 200 # number of simulated sample for each job, default: 200, test: 20\n",
    "assert sample_size % n_batch == 0\n",
    "batches = [x+1 for x in range(n_batch)]\n",
    "input: for_each = ['batches']\n",
    "output: f\"{cwd:a}/{cnv_type}_simu/{_input[0]:bn}.sample.{_batches}.gz\"\n",
    "python: expand = '${ }'\n",
    "    import pandas as pd, numpy as np\n",
    "    import random, itertools, ast\n",
    "    data = pd.read_csv(${_input:r}, compression = \"gzip\", header = None, sep = \"\\t\")\n",
    "    size = int(${sample_size} / ${n_batch})\n",
    "    random.seed(${_batches})\n",
    "    samples_genome = list()\n",
    "    for i in range(size):\n",
    "        order = random.sample(data.index.tolist(), data.shape[1])\n",
    "        s = list(itertools.chain(*list(ast.literal_eval(n) for n in np.diag(data.loc[order, :]))))\n",
    "        samples_genome.append(s)\n",
    "    samples_genome_df = pd.DataFrame(samples_genome) # row: sample, column: gene\n",
    "    samples_genome_df.to_csv(${_output:r}, compression = \"gzip\", sep = \"\\t\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[simulate_4]\n",
    "input: group_by = 'all'\n",
    "output: f'{_input[0]:nn}.combined.gz'\n",
    "bash: expand = \"${ }\"\n",
    "    zcat ${_input} | gzip > ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[simulate_5]\n",
    "# shape = 3; scale = 1 for gamma\n",
    "# shape = 2.191013; scale = 0.2682398 for normal\n",
    "parameter: shape = 3.0 # mean for normal (1), shape for gamma (3)\n",
    "parameter: scale = 1.0 # se for normal (0.5), scale for gamma (1)\n",
    "# 'gamma' or 'normal'\n",
    "parameter: beta_method = 'normal'\n",
    "parameter: penetrance = 0.05\n",
    "parameter: seed = 999999\n",
    "parameter: ctrl_case_ratio = 1.0\n",
    "parameter: pi0 = 0.95\n",
    "output: f'{_input:nn}.X.gz', f'{_input:nn}.y', f'{_input:nn}.beta'\n",
    "python: expand = \"${ }\"\n",
    "    import pandas as pd, numpy as np\n",
    "    np.random.seed(${seed})\n",
    "    # For normal distribution the -3*sigma to 3*sigma on x-axis should correspond to\n",
    "    # log(4) and log(20). The shape and scale parameters are thus:\n",
    "    # mu = (log(20) + log(4))/2 = 2.191013; sigma = (log(20) - mu) / 3 = 0.2682398\n",
    "    def logor_gamma(shape, scale, n):\n",
    "        return np.log(np.random.gamma(shape, scale, n))\n",
    "\n",
    "    def logor_normal(mean, se, n):\n",
    "        return np.random.normal(mean, se, n)\n",
    "\n",
    "    data = pd.read_csv(${_input:r}, compression = \"gzip\", sep = \"\\t\", header = None)\n",
    "    beta0 = np.log(${penetrance} / (1-${penetrance}))\n",
    "    beta1s = [x for x in logor_${beta_method}(${shape}, ${scale}, data.shape[1])]\n",
    "    beta1s = [np.random.binomial(1, 1-${pi0}) * i for i in beta1s]\n",
    "    with open(${_output[2]:r}, 'w') as f:\n",
    "        f.write(\"\\n\".join([str(b) for b in beta1s]))\n",
    "    logit_y = np.matmul(data.values, beta1s) + beta0\n",
    "    ys_p = np.exp(logit_y) / (1+np.exp(logit_y))\n",
    "    ys = np.random.binomial(1, ys_p)\n",
    "    case_index = np.ravel(np.where(ys == 1))\n",
    "    ctrl_index = sorted(np.random.choice(np.ravel(np.where(ys == 0)), int(len(case_index) * ${ctrl_case_ratio})))\n",
    "    genotype = data.iloc[case_index.tolist() + ctrl_index, :]\n",
    "    genotype.to_csv(${_output[0]:r}, compression = \"gzip\", sep = \"\\t\", header = False, index = False)\n",
    "    with open(${_output[1]:r}, 'w') as f:\n",
    "        f.write('\\n'.join(['1'] * len(case_index) + ['0'] * len(ctrl_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_2]\n",
    "depends: R_library(\"data.table\"), R_library('susieR'), R_library(\"reticulate\")\n",
    "parameter: L = 1\n",
    "parameter: pve = 0.005\n",
    "parameter: method = \"optim\"\n",
    "suffix = f\"SuSiE.L_{L}.prior_{fmtP(pve)}\"\n",
    "output: f\"{_input[0]:n}.{suffix}.susie.rds\"\n",
    "R: expand = '${ }', stderr = f'{_input[0]:n}.stderr', stdout = f'{_input[0]:n}.stdout'\n",
    "    library(susieR)\n",
    "    library(data.table)\n",
    "    library(reticulate)\n",
    "    library(varbvs)\n",
    "    X <- as.matrix(data.table::fread(${_input[0]:r}, header = F))\n",
    "    bound <- as.matrix(data.table::fread(${_input[1]:r}, header = T))\n",
    "    y <- as.matrix(data.table::fread(\"${phenotype_file}\"))\n",
    "    storage.mode(X) = 'double'\n",
    "    storage.mode(y) = 'double'\n",
    "    res <- list()\n",
    "    res_varbvs <- list()\n",
    "    for (row in 1:nrow(bound)){\n",
    "        x <- as.matrix(X[, as.character(bound[row,1]:bound[row,2])])\n",
    "        # print (head(x))\n",
    "        res_x <- susie(x, y, L = ${L}, scaled_prior_variance = ${pve}, estimate_prior_method = '${method}')\n",
    "        res[[row]] <- res_x\n",
    "        logodds <- seq(-log10(ncol(x)), 1, length.out = 40)\n",
    "        fit <- varbvs::varbvs(x, NULL, y, logodds = logodds, verbose = FALSE)\n",
    "        b <- as.vector(coef(fit)[, \"averaged\"])\n",
    "        res1_x <- list(fit = fit, mu = b[1], beta = b[-1])\n",
    "        res_varbvs[[row]] <- res1_x\n",
    "    }\n",
    "    saveRDS(res, ${_output[0]:r})\n",
    "    saveRDS(res_varbvs, ${_output[1]:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[varbvs_2]\n",
    "depends: R_library(\"data.table\"), R_library(\"reticulate\"), R_library(\"varbvs\")\n",
    "output: f\"{_input[0]:n}.varbvs.rds\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[get_hist_2]\n",
    "output: f\"{_input[0]:n}.histogram.pdf\"\n",
    "python: expand = '${ }'\n",
    "    import pandas as pd, matplotlib.pyplot as plt\n",
    "    blocks = pd.read_csv(${_input[1]:r}, sep = \"\\t\", header = 0)\n",
    "    spans = [j-i+1 for i,j in zip(blocks[\"block_start\"], blocks[\"block_end\"])]\n",
    "    counts = {i: spans.count(i) for i in set(spans) if i != 0}\n",
    "    fig, ax = plt.subplots(figsize = (8,6))\n",
    "    plt.bar(list(counts.keys()), list(counts.values()), width = 0.8)\n",
    "    ax.set_title(\"Histogram of number of genes in blocks\")\n",
    "    plt.savefig(${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Note\n",
    "```\n",
    "cd ~/GIT/cnv-gene-mapping\n",
    "sos run dsc/20190717_workflow.ipynb get_hist:1-2 -s build\n",
    "sos run dsc/20190717_workflow.ipynb get_hist:1-2 --genotype_file /home/min/GIT/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.X.gz\n",
    "sos run dsc/20190717_workflow.ipynb analyze:1-2 -s build\n",
    "sos run dsc/20190717_workflow.ipynb analyze:1-2 --simu_pheno /home/min/GIT/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.y -s build\n",
    "sos run dsc/20190717_workflow.ipynb simulate:1-5 --n_gene_in_block 30 --shape 1 --scale 0.5 -s build\n",
    "sos run dsc/20190717_workflow.ipynb -s build -j 6\n",
    "```\n",
    "```\n",
    "sinteractive --time=01:00:00 --partition=bigmem2 --nodes=1 --ntasks-per-node=1 --mem-per-cpu=100G\n",
    "sos run dsc/20190717_workflow.ipynb simulate:1-5 --n_gene_in_block 30 --shape 1 --scale 0.5 -s build\n",
    "\n",
    "sos run dsc/20190717_workflow.ipynb get_hist:1-2 --genotype_file /home/gaow/GIT/github/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.X.gz \\\n",
    "--phenotype_file /home/gaow/GIT/github/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.y --n_gene_in_block 1 -s build\n",
    "\n",
    "sos run dsc/20190717_workflow.ipynb analyze:1-2 --genotype_file /home/gaow/GIT/github/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.X.gz \\\n",
    "--phenotype_file /home/gaow/GIT/github/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.y --n_gene_in_block 1 \\\n",
    "--simu_pheno /home/gaow/GIT/github/cnv-gene-mapping/data/deletion_simu/deletion.genes.block30.for_simu.sample.y --real \"FALSE\" -s build\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFD91A"
    ],
    [
     "R",
     "ir",
     "R",
     "#DCDCDA"
    ],
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.20.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
