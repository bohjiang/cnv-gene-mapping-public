{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import math\n",
    "from collections import Counter\n",
    "import scipy.special\n",
    "from scipy.misc import logsumexp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from fisher import pvalue\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def load_reference_gene(filename):\n",
    "    '''Load reference gene database'''\n",
    "    ref_gene = pd.read_table(filename, compression=\"gzip\", sep=\"\\t\", \n",
    "                         header = None, usecols=(1,2,4,5,12), \n",
    "                         names = [\"tx_name\", \"chrom\", \"tx_start\", \"tx_end\", \"gene_name\"])\n",
    "    return ref_gene.drop_duplicates(subset=(\"chrom\", \"tx_start\", \"tx_end\"))\n",
    "\n",
    "def load_cnv_data(filename):\n",
    "    '''load cnv data'''\n",
    "    cnvbed = {}\n",
    "    dataset = None\n",
    "    for line in open(filename).readlines():\n",
    "        if not line.startswith(\"chr\"):\n",
    "            dataset = line.strip().split()[1].lstrip(\"name=\")\n",
    "            cnvbed[dataset] = {}\n",
    "            continue\n",
    "        line = line.strip().split()\n",
    "        if not line[0] in cnvbed[dataset]:\n",
    "            cnvbed[dataset][line[0]] = []\n",
    "        cnvbed[dataset][line[0]].append((int(line[1]),int(line[2])))\n",
    "\n",
    "    for dataset in cnvbed.keys():\n",
    "        for chrom in cnvbed[dataset]:\n",
    "            cnvbed[dataset][chrom].sort()\n",
    "\n",
    "    cnvbed_df = {}\n",
    "    for dataset in cnvbed.keys():\n",
    "        cnvbed_df[dataset] = {\"chrom\":[], \"cnv_start\":[], \"cnv_end\":[]}\n",
    "        for chrom in cnvbed[dataset]:\n",
    "            start, end = tuple(zip(*cnvbed[dataset][chrom])) \n",
    "            cnvbed_df[dataset][\"chrom\"].extend([chrom] * len(start))\n",
    "            cnvbed_df[dataset][\"cnv_start\"] += list(start)\n",
    "            cnvbed_df[dataset][\"cnv_end\"] += list(end)\n",
    "        cnvbed_df[dataset] = pd.DataFrame.from_dict(cnvbed_df[dataset]).drop_duplicates(\n",
    "                                                subset=(\"chrom\", \"cnv_start\", \"cnv_end\"))\n",
    "    return cnvbed_df\n",
    "\n",
    "def count_cnv_by_block(df, block_size):\n",
    "    # check how many CNVs start in block_size = 100K blocks genome\n",
    "    # this cell produces `block_counts`: ((chrom, block_position), count)\n",
    "    def count_by_blocks(chrom):\n",
    "        data = df.query('chrom == \"{}\"'.format(chrom))['cnv_start'].tolist()\n",
    "        start_pos = min(data)\n",
    "        end_pos = max(data)\n",
    "        counts, bins = np.histogram(data, bins = int((end_pos - start_pos) / block_size) + 1, \n",
    "                                range = (start_pos, end_pos))\n",
    "        return counts, [int(x) for x in bins]    \n",
    "    #\n",
    "    block_counts = []\n",
    "    for chrom in set(df['chrom']):\n",
    "        counts, bins = count_by_blocks(chrom)\n",
    "        block_counts.extend([((chrom, x), y) for x, y in zip(bins, counts)])\n",
    "    return block_counts\n",
    "\n",
    "def fit_truncated_gaussian_mix(x, k = 10):\n",
    "    x = x.extend([-i for i in x])\n",
    "    clf = GaussianMixture(n_components=1, covariance_type='full')\n",
    "    clf.fit(x)\n",
    "    return clf\n",
    "\n",
    "def sample_cnv_length(data, mean_num_cnv):\n",
    "    return np.random.choice(data, np.random.poisson(mean_num_cnv))\n",
    "\n",
    "def get_sample_blocks(block_counts, num_cnv):\n",
    "    '''sample blocks from blocks across genome'''\n",
    "    probability_distribution = np.array([x[1] for x in block_counts])\n",
    "    sample_idx = np.random.choice(range(len(block_counts)), num_cnv, \n",
    "                                  p = probability_distribution / sum(probability_distribution))\n",
    "    return sorted([block_counts[idx][0] for idx in sample_idx])\n",
    "\n",
    "def assign_cnv_to_sample(sample_blocks, sample_len, block_size):\n",
    "    samples = {'chrom': [], 'cnv_start': [], 'cnv_terminate': []}\n",
    "    for x, y in zip(sample_blocks, sample_len):\n",
    "        start_pos = randint(x[1], x[1] + block_size)\n",
    "        samples['cnv_start'].append(start_pos)\n",
    "        samples['cnv_terminate'].append(start_pos + int(y))\n",
    "        samples['chrom'].append(x[0])\n",
    "    return pd.DataFrame(samples)\n",
    "\n",
    "def annotate_samples(samples, gene_df):\n",
    "    query = \"\"\"\n",
    "        SELECT cnv.chrom, cnv.cnv_start, cnv.cnv_terminate, gene.tx_name, gene.gene_name\n",
    "        FROM samples cnv LEFT JOIN gene_df gene\n",
    "        WHERE cnv.chrom == gene.chrom \n",
    "        AND (\n",
    "        (cnv.cnv_start >= gene.tx_start AND cnv.cnv_start <= gene.tx_end)\n",
    "        OR\n",
    "        (cnv.cnv_terminate >= gene.tx_start AND cnv.cnv_terminate <= gene.tx_end)\n",
    "        OR\n",
    "        (cnv.cnv_start <= gene.tx_start AND cnv.cnv_terminate >= gene.tx_end)\n",
    "        )\n",
    "        \"\"\"\n",
    "        # drop_duplicates(): make sure the case that CNV spread multiple txs but one gene to be counted only once\n",
    "    return sqldf(query).drop_duplicates(subset=(\"chrom\", \"cnv_start\", \"cnv_terminate\", \"gene_name\"))\n",
    "\n",
    "def get_causal_genes(causal_genes, sample_genes):\n",
    "    '''get causal genes'''\n",
    "    return [x for x in causal_genes if x in sample_genes]\n",
    "\n",
    "def get_ccnv():\n",
    "    '''get causal cnvs'''\n",
    "    return None\n",
    "    \n",
    "def p_case(p, num_causal_genes_in_sample, sim_args):\n",
    "    if num_causal_genes_in_sample == 0:\n",
    "        return p\n",
    "    baseline_odds = p / (1 - p)\n",
    "    odds_ratio = np.prod([np.random.gamma(sim_args[\"odds_ratio_params\"]['shape'], \n",
    "                                          sim_args[\"odds_ratio_params\"]['scale']) \n",
    "                          for x in range(num_causal_genes_in_sample)])\n",
    "    odds = baseline_odds * odds_ratio\n",
    "    return odds / (1 + odds)\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.args = {'block_size': 100000,\n",
    "                     'avg_cnv_per_individual': 5,\n",
    "                     'n_case': 1,\n",
    "                     'n_ctrl': 1,\n",
    "                     # set Gamma shape to be 3 instead of 5\n",
    "                     'odds_ratio_params': {'shape': 3, 'scale': 1},\n",
    "                     'prevalence': 0.005\n",
    "                    }\n",
    "        \n",
    "        self.causal_genes = {\n",
    "            \"causal_genes_del\": ['RAB2B', 'CHD8', 'TOX4', 'SNORD8', 'METTL3', 'SALL2', 'SNORD9', 'SUPT16H', \n",
    "                                 'RPGRIP1', 'MIR3180-3', 'MIR3670-1', 'NOMO2', 'MIR6511A4', 'NPIPA8', 'FSIP2', \n",
    "                                 'FSIP2-AS1', 'LOC101927196', 'ATP6V1E1', 'BCL2L13', 'BID', 'CECR1', 'CECR2', \n",
    "                                 'CECR3', 'CECR5', 'CECR5-AS1', 'CECR6', 'CECR7', 'FLJ41941', 'GAB4', 'IL17RA', \n",
    "                                 'LINC00528', 'LOC100996342', 'LOC100996415', 'LOC101929372', 'LOC105379550', \n",
    "                                 'MICAL3', 'MIR3198-1', 'MIR648', 'PEX26', 'SLC25A18', 'TUBA8', 'USP18', 'FAM72C', \n",
    "                                 'FAM72D', 'LINC01138', 'NBPF8', 'PPIAL4G', 'MIR6770-2', 'MIR3179-1', 'MIR3180-2', \n",
    "                                 'MACROD2', 'FAM189A1', 'LOC100130111', 'MACROD2-AS1', 'LINC00623', 'LINC00869', \n",
    "                                 'PPIAL4C', 'MIR3680-2', 'ABCC6P1', 'HNRNPC', 'APBA2', 'C22orf39', 'CDC45', 'CLDN5',\n",
    "                                 'CLTCL1', 'DGCR14', 'DGCR2', 'GNB1L', 'GOLGA6L7P', 'GOLGA8M', 'GP1BB', 'GSC2', \n",
    "                                 'HIRA', 'LINC00895', 'LINC01311', 'LOC100289656', 'MRPL40', 'NPIPB4', 'NSMCE3', \n",
    "                                 'PDCD6IPP2', 'SEPT5', 'SEPT5-GP1BB', 'SLC25A1', 'TBX1', 'TSSK2', 'UFD1L', \n",
    "                                 'WHAMMP2', 'HSFY1P1', 'PFN1P2', 'XKR3', 'OR4A47', 'C5orf17', 'CNTN4', 'EXOC4', \n",
    "                                 'LINC00540', 'LOC101927967', 'LRRC4C', 'SMG1P2', 'SPRY2', 'LOC100288162'],\n",
    "            \"causal_genes_dup\": ['CHN2', 'ESYT2', 'KIF26B', 'RPGRIP1', 'C22orf39', 'CDAN1', 'CDC45', 'CLDN5', \n",
    "                                 'GNB1L', 'GP1BB', 'HIRA', 'LINC00895', 'MRPL40', 'SEPT5', 'SEPT5-GP1BB', 'STARD9', \n",
    "                                 'TBX1', 'TTBK2', 'UFD1L', 'LOC283177', 'AGAP6', 'COL18A1', 'COL18A1-AS1', \n",
    "                                 'FAM21EP', 'LOC440910', 'MIR6815', 'POTEE', 'SLC19A1', 'TIMM23B', 'VAV2', \n",
    "                                 'WASHC2A', 'PTPRN2', 'ANO2', 'CCNDBP1', 'COLEC12', 'EPB42', 'FAM118A', 'FAM160A1', \n",
    "                                 'FBLN1', 'KIAA0930', 'LINC01589', 'LOC100996325', 'LOC728613', 'LRRIQ3', 'MACROD2', \n",
    "                                 'MIR1249', 'NUP153', 'NUP50', 'NUP50-AS1', 'PRSS48', 'RAP1GAP2', 'RBM47', 'RIBC2', \n",
    "                                 'SH3D19', 'SMC1B', 'TGM5', 'TMEM62', 'UPK3A', 'VWF', 'DGKH', 'KIF13A', 'LINC01266', \n",
    "                                 'VWA8', 'VWA8-AS1', 'CRYM-AS1', 'SNX29P1', 'KCNJ12', 'KCNJ18', 'BNC1', \n",
    "                                 'LOC105375545', 'MIR128-2', 'AGAP7P', 'BTBD11', 'C3orf67', 'CHD8', 'COL18A1-AS2', \n",
    "                                 'FAM110C', 'GMDS', 'HIRIP3', 'INO80E', 'LINC01022', 'MARK3', 'MIR5707', 'MSMB', \n",
    "                                 'NCAPG2', 'NCOA4', 'PAK5', 'PLEKHB2', 'PWP1', 'RAB2B', 'RNF103-CHMP3', 'SNORD8', \n",
    "                                 'SNORD9', 'SUPT16H', 'TIMM23', 'ZCCHC14', 'C17orf51', 'COX20', 'DLG1', 'EFCAB2']\n",
    "        }\n",
    "\n",
    "    def print(self, do_not_print = False):\n",
    "        if not do_not_print:\n",
    "            print(\"Number of causal deletion genes {}\".format(len(self.causal_genes)))\n",
    "        self.a_new_one = 'hello'\n",
    "\n",
    "env = Environment()\n",
    "        \n",
    "def simulate(refgene, cnv_data, args, causal_genes):\n",
    "    df = cnv_data.drop_duplicates(subset=(\"chrom\", \"cnv_start\", \"cnv_end\"))\n",
    "    block_counts = count_cnv_by_block(df, args['block_size'])\n",
    "    cnv_length = cnv_data['cnv_end'] - cnv_data['cnv_start']\n",
    "    status = 1\n",
    "    case_data = []\n",
    "    ctrl_data = []\n",
    "    debug = {'p': [], 'niter': 0, 'time': [str(datetime.now()), None]}\n",
    "    \n",
    "    while(status):\n",
    "        sample_len = sample_cnv_length(cnv_length, args['avg_cnv_per_individual'])\n",
    "        sample_blocks = get_sample_blocks(block_counts, len(sample_len))\n",
    "        samples = assign_cnv_to_sample(sample_blocks, sample_len, args['block_size'])\n",
    "        samples = annotate_samples(samples, refgene)\n",
    "        causal_genes_in_sample = get_causal_genes(causal_genes, samples['gene_name'].tolist())\n",
    "        p = p_case(args['prevalence'], len(causal_genes_in_sample), args)\n",
    "        #debug['p'].append(p)\n",
    "        if random.random() < p and len(case_data) < args['n_case']:\n",
    "            # sample data is a case\n",
    "            case_data.append(samples)\n",
    "            debug['p'].append(p)\n",
    "        if random.random() > p and len(ctrl_data) < args['n_ctrl']:\n",
    "            ctrl_data.append(samples)\n",
    "            debug['p'].append(p)\n",
    "        if len(case_data) == args['n_case'] and len(ctrl_data) == args['n_ctrl']:\n",
    "            status = 0\n",
    "        debug['niter'] += 1\n",
    "    debug['time'][1] = str(datetime.now())\n",
    "    return {'case': case_data, 'ctrl': ctrl_data, 'debug': debug}\n",
    "\n",
    "def save_data(data, filename):\n",
    "    pickle.dump(data, open(filename, \"wb\"))\n",
    "\n",
    "def load_data(filename):\n",
    "    return pickle.load(open(filename, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook simulation_simplify.ipynb to script\n",
      "[NbConvertApp] Writing 10727 bytes to simulation_simplify.py\n"
     ]
    }
   ],
   "source": [
    "! jupyter nbconvert --to script simulation_simplify.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
