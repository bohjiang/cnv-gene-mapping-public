{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "# Python utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "This is a centralized script for all Python functions / classes ever used repeatedly, exported as Python module `utils.py`. **This notebook should not / cannot be executed as is!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import random\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import glob\n",
    "import math\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from fisher import pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## File I/O functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "def load_reference_gene(filename):\n",
    "    '''Load reference gene database'''\n",
    "    ref_gene = pd.read_table(filename, compression=\"gzip\", sep=\"\\t\", \n",
    "                         header = None, usecols=(1,2,4,5,12), \n",
    "                         names = [\"tx_name\", \"chrom\", \"tx_start\", \"tx_end\", \"gene_name\"])\n",
    "    return ref_gene.drop_duplicates(subset=(\"chrom\", \"tx_start\", \"tx_end\"))\n",
    "\n",
    "def load_pthwy_gene(filename, n_skiprow = 2):\n",
    "    '''Load pathway genes. For example, calcium pathway genes.\n",
    "       The input file must contain a column named \"gene_name\".\n",
    "    '''\n",
    "    pthwy_gene = pd.read_table(filename, skiprows = n_skiprow, header = None, names = [\"gene_name\"])\n",
    "    return pthwy_gene\n",
    "\n",
    "def load_cnv_data(filename):\n",
    "    '''load cnv data'''\n",
    "    cnvbed = {}\n",
    "    dataset = None\n",
    "    for line in open(filename).readlines():\n",
    "        if not line.startswith(\"chr\"):\n",
    "            dataset = line.strip().split()[1].lstrip(\"name=\")\n",
    "            cnvbed[dataset] = {}\n",
    "            continue\n",
    "        line = line.strip().split()\n",
    "        if not line[0] in cnvbed[dataset]:\n",
    "            cnvbed[dataset][line[0]] = []\n",
    "        cnvbed[dataset][line[0]].append((int(line[1]),int(line[2])))\n",
    "\n",
    "    for dataset in cnvbed.keys():\n",
    "        for chrom in cnvbed[dataset]:\n",
    "            cnvbed[dataset][chrom].sort()\n",
    "\n",
    "    cnvbed_df = {}\n",
    "    for dataset in cnvbed.keys():\n",
    "        cnvbed_df[dataset] = {\"chrom\":[], \"cnv_start\":[], \"cnv_end\":[]}\n",
    "        for chrom in cnvbed[dataset]:\n",
    "            start, end = tuple(zip(*cnvbed[dataset][chrom])) \n",
    "            cnvbed_df[dataset][\"chrom\"].extend([chrom] * len(start))\n",
    "            cnvbed_df[dataset][\"cnv_start\"] += list(start)\n",
    "            cnvbed_df[dataset][\"cnv_end\"] += list(end)\n",
    "        cnvbed_df[dataset] = pd.DataFrame.from_dict(cnvbed_df[dataset]).drop_duplicates(\n",
    "                                                subset=(\"chrom\", \"cnv_start\", \"cnv_end\"))\n",
    "    return cnvbed_df\n",
    "\n",
    "def save_data(data, filename):\n",
    "    pickle.dump(data, open(filename, \"wb\"))\n",
    "\n",
    "def load_data(filename):\n",
    "    return pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "class Environment(dict):\n",
    "    def __init__(self):\n",
    "        parameters = {'block_size': 100000,\n",
    "                      'avg_cnv_per_individual': 5,\n",
    "                      'n_case': 5,\n",
    "                      'n_ctrl': 5,\n",
    "                       # set Gamma shape to be 3 instead of 5\n",
    "                       # 'odds_ratio_params' : None # for H_0\n",
    "                      'odds_ratio_params': {'shape': 25, 'scale': 1},\n",
    "                      'prevalence': 0.005,\n",
    "                      'n_causal_gene': 200,\n",
    "                      'refgene_file': '../data/refGene.txt.gz',\n",
    "                      'pthwy_gene_file': '../data/calciumgeneset.txt',\n",
    "                      'cnv_file': '../data/ISC-r1.CNV.bed',\n",
    "                      'case_dataset': 'delCases',\n",
    "                      'ctrl_dataset': 'delControls',\n",
    "                      'output': 'del_sample',\n",
    "                      'ncpu': 6\n",
    "                     }\n",
    "        self.update(parameters)\n",
    "        ## select causal genes randomly, instead of the first 100 in enrichment analysis\n",
    "#         self.ref_gene_name = load_reference_gene(parameters[\"refgene_file\"])[\"gene_name\"].tolist()\n",
    "#         self.causal_genes = random.sample(self.ref_gene_name, parameters['n_causal_gene'])\n",
    "        self.causal_genes = load_pthwy_gene(parameters[\"pthwy_gene_file\"])[\"gene_name\"].tolist()\n",
    "        self.seed = 12\n",
    "\n",
    "args = Environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## CNV data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "def count_cnv_by_block(df, block_size):\n",
    "    # check how many CNVs start in block_size = 100K blocks genome\n",
    "    # this cell produces `block_counts`: ((chrom, block_position), count)\n",
    "    def count_by_blocks(chrom):\n",
    "        data = df.query('chrom == \"{}\"'.format(chrom))['cnv_start'].tolist()\n",
    "        start_pos = min(data)\n",
    "        end_pos = max(data)\n",
    "        counts, bins = np.histogram(data, bins = int((end_pos - start_pos) / block_size) + 1, \n",
    "                                    range = (start_pos, end_pos))\n",
    "        return counts, [int(x) for x in bins]\n",
    "    block_counts = []\n",
    "    for chrom in set(df['chrom']):\n",
    "        counts, bins = count_by_blocks(chrom)\n",
    "        # most blocks contain 0 CNV start. Add 0.5 to each block, so that CNV could start within any block.\n",
    "        block_counts.extend([((chrom, x), y+0.5) for x, y in zip(bins, counts)])\n",
    "    return block_counts\n",
    "\n",
    "def fit_truncated_gaussian_mix(x, k = 10):\n",
    "    x = x.extend([-i for i in x])\n",
    "    clf = GaussianMixture(n_components=1, covariance_type='full')\n",
    "    clf.fit(x)\n",
    "    return clf\n",
    "\n",
    "def sample_cnv_length(data, mean_num_cnv):\n",
    "    return np.random.choice(data, np.random.poisson(mean_num_cnv))\n",
    "\n",
    "def get_sample_blocks(block_counts, num_cnv):\n",
    "    '''sample blocks from blocks across genome'''\n",
    "    probability_distribution = np.array([x[1] for x in block_counts])\n",
    "    sample_idx = np.random.choice(range(len(block_counts)), num_cnv, \n",
    "                                  p = probability_distribution / sum(probability_distribution))\n",
    "    return sorted([block_counts[idx][0] for idx in sample_idx])\n",
    "\n",
    "def assign_cnv_to_sample(sample_blocks, sample_len, block_size):\n",
    "    samples = {'chrom': [], 'cnv_start': [], 'cnv_terminate': []}\n",
    "    for x, y in zip(sample_blocks, sample_len):\n",
    "        start_pos = randint(x[1], x[1] + block_size)\n",
    "        samples['cnv_start'].append(start_pos)\n",
    "        samples['cnv_terminate'].append(start_pos + int(y))\n",
    "        samples['chrom'].append(x[0])\n",
    "    return pd.DataFrame(samples)\n",
    "\n",
    "def annotate_samples(samples, gene_df):\n",
    "    query = \"\"\"\n",
    "        SELECT cnv.chrom, cnv.cnv_start, cnv.cnv_terminate, gene.tx_name, gene.gene_name\n",
    "        FROM samples cnv LEFT JOIN gene_df gene\n",
    "        WHERE cnv.chrom == gene.chrom \n",
    "        AND (\n",
    "        (cnv.cnv_start >= gene.tx_start AND cnv.cnv_start <= gene.tx_end)\n",
    "        OR\n",
    "        (cnv.cnv_terminate >= gene.tx_start AND cnv.cnv_terminate <= gene.tx_end)\n",
    "        OR\n",
    "        (cnv.cnv_start <= gene.tx_start AND cnv.cnv_terminate >= gene.tx_end)\n",
    "        )\n",
    "        \"\"\"\n",
    "        # drop_duplicates(): make sure the case that CNV spread multiple txs but each gene to be counted only once\n",
    "    return sqldf(query).drop_duplicates(subset=(\"chrom\", \"cnv_start\", \"cnv_terminate\", \"gene_name\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Simulation related codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "def get_causal_genes(causal_genes, sample_genes):\n",
    "    '''get causal genes for each simulated sample'''\n",
    "    return [x for x in causal_genes if x in sample_genes]\n",
    "\n",
    "def get_ccnv():\n",
    "    '''get causal cnvs'''\n",
    "    return None\n",
    "    \n",
    "def p_case(p, num_causal_genes_in_sample, shape, scale):\n",
    "    if num_causal_genes_in_sample == 0:\n",
    "        return p\n",
    "    baseline_odds = p / (1 - p)\n",
    "    if shape is None or scale is None:\n",
    "        odds_ratio = 1\n",
    "    else:\n",
    "        odds_ratio = np.prod([np.random.gamma(shape, scale) \n",
    "                              for x in range(num_causal_genes_in_sample)])\n",
    "    # obtain the power of fisher test by setting odds ratio to 1\n",
    "    # odds_ratio = 1\n",
    "    odds = baseline_odds * odds_ratio\n",
    "    return odds / (1 + odds)\n",
    "\n",
    "def simulate_core(case_data, ctrl_data, debug, args, cnv_length, block_counts, refgene, N1, N2):\n",
    "    cnt1 = 0\n",
    "    cnt2 = 0\n",
    "    status = 1\n",
    "    while(status):\n",
    "        sample_len = sample_cnv_length(cnv_length, args[\"avg_cnv_per_individual\"])\n",
    "        sample_blocks = get_sample_blocks(block_counts, len(sample_len))\n",
    "        samples = assign_cnv_to_sample(sample_blocks, sample_len, args[\"block_size\"])\n",
    "        samples = annotate_samples(samples, refgene)\n",
    "        causal_genes_in_sample = get_causal_genes(args.causal_genes, samples['gene_name'].tolist())\n",
    "        p = p_case(args[\"prevalence\"], len(causal_genes_in_sample), \n",
    "                   args[\"odds_ratio_params\"][\"shape\"], args[\"odds_ratio_params\"][\"scale\"])\n",
    "        if random.random() < p and cnt1 < N1:\n",
    "            # sample data is a case\n",
    "            case_data.append(samples)\n",
    "            debug_data = dict(debug)\n",
    "            debug_data['p in case'].append(p)\n",
    "            debug_data['number of causal genes in case'].append(len(causal_genes_in_sample))\n",
    "            debug_data['simulated CNV length in case'].extend(sample_len)\n",
    "            debug_data['number of genes overlap CNV in case'].append(len(set(samples['gene_name'].tolist())))\n",
    "            debug.update(debug_data)\n",
    "            cnt1 += 1\n",
    "        if random.random() > p and cnt2 < N2:\n",
    "            # sample data is a control\n",
    "            ctrl_data.append(samples)\n",
    "            debug_data = dict(debug)\n",
    "            debug_data['p in ctrl'].append(p)\n",
    "            debug_data['number of causal genes in ctrl'].append(len(causal_genes_in_sample))\n",
    "            debug_data['simulated CNV length in ctrl'].extend(sample_len)\n",
    "            debug_data['number of genes overlap CNV in ctrl'].append(len(set(samples['gene_name'].tolist())))\n",
    "            debug.update(debug_data)\n",
    "            cnt2 += 1\n",
    "        if cnt1 == N1 and cnt2 == N2:\n",
    "            status = 0\n",
    "    return status\n",
    "\n",
    "def simulate(refgene, cnv_data, args):\n",
    "    from multiprocessing import Pool, Manager\n",
    "    manager = Manager()\n",
    "    np.random.seed(args.seed)\n",
    "    df = cnv_data.drop_duplicates(subset=(\"chrom\", \"cnv_start\", \"cnv_end\"))\n",
    "    block_counts = count_cnv_by_block(df, args['block_size'])\n",
    "    cnv_length = df['cnv_end'] - df['cnv_start']\n",
    "    debug = {'p in case': [], 'p in ctrl': [], 'args': dict(args), 'time': [str(datetime.now()), None],\n",
    "             'causal genes': args.causal_genes, 'number of genes overlap CNV in case': [], \n",
    "             'number of genes overlap CNV in ctrl': [],\n",
    "             'number of causal genes in case': [], 'number of causal genes in ctrl': [], \n",
    "             'simulated CNV length in case': [], 'simulated CNV length in ctrl': [], 'seed': args.seed}\n",
    "    manager = Manager()\n",
    "    case_data = manager.list()\n",
    "    ctrl_data = manager.list()\n",
    "    debug = manager.dict(debug)\n",
    "    pool = Pool(args['ncpu'])\n",
    "    N1 = [1] * args['n_case'] + [0] * args['n_ctrl']\n",
    "    N2 = [0] * args['n_case'] + [1] * args['n_ctrl']\n",
    "    # elog saves exceptions\n",
    "    elog = [pool.apply_async(simulate_core, args = (case_data, ctrl_data, debug, args, cnv_length, block_counts, refgene, x, y)) \n",
    "            for x, y in zip(N1, N2)]\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for item in elog:\n",
    "        item.get()\n",
    "    debug = dict(debug)\n",
    "    debug['time'][1] = str(datetime.now())\n",
    "    return {'case': list(case_data), 'ctrl': list(ctrl_data), 'debug': debug}\n",
    "\n",
    "def run_simulation(args, simulation_id = None):\n",
    "    ref_gene = load_reference_gene(args['refgene_file'])\n",
    "    cnv_data = load_cnv_data(args['cnv_file'])\n",
    "    sample_data = simulate(ref_gene, pd.concat([cnv_data[args['case_dataset']], cnv_data[args['ctrl_dataset']]]),\n",
    "                           args)\n",
    "    save_data(sample_data, '{}{}.data.pkl'.\\\n",
    "              format(args['output'], '_{}'.format(simulation_id) if simulation_id is not None else ''))\n",
    "    return sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Codes for data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "def get_analysis_blocks(data):\n",
    "    '''Determine from `data` table (pd.DataFrame) independent genomic blocks.\n",
    "       For simulated samples use `pd.concat([pd.concat(samples['case']), pd.concat(samples['ctrl'])])`\n",
    "       as input'''\n",
    "    from scipy.sparse.csgraph import connected_components\n",
    "    #\n",
    "    def reductionFunction(df):\n",
    "        # create a 2D graph of connectivity between date ranges\n",
    "        start = df.cnv_start.values\n",
    "        end = df.cnv_terminate.values\n",
    "        graph = (start <= end[:, None]) & (end >= start[:, None])\n",
    "        n_components, indices = connected_components(graph)\n",
    "        return df.groupby(indices).aggregate({'cnv_start': 'min',\n",
    "                                              'cnv_terminate': 'max',\n",
    "                                              'tx_name': lambda x: ','.join(sorted(set(x))),\n",
    "                                              'gene_name': lambda x: ','.join(sorted(set(x)))})\n",
    "    return [x.split(',') for x in data.groupby(['chrom']).apply(reductionFunction).reset_index('chrom')['gene_name'].tolist()]\n",
    "\n",
    "def get_gene_table(gene_df):\n",
    "    gene_table = {}\n",
    "    for item in [\"case\", \"ctrl\"]:\n",
    "        gene = pd.concat(gene_df[item])\n",
    "        query = '''\n",
    "        SELECT chrom, gene_name, count(gene_name)\n",
    "        FROM gene\n",
    "        GROUP BY chrom, gene_name\n",
    "        ORDER BY count(gene_name) DESC\n",
    "        '''\n",
    "        gene_table[item] = sqldf(query)\n",
    "    gene_table = pd.merge(gene_table[\"case\"], gene_table[\"ctrl\"], how = \"outer\", on = [\"chrom\", \"gene_name\"])\n",
    "    gene_table[\"count(gene_name)_x\"].fillna(0, inplace=True)\n",
    "    gene_table[\"count(gene_name)_y\"].fillna(0, inplace=True)\n",
    "    gene_table = gene_table.rename(columns={\"count(gene_name)_x\": \"n_case_gene\", \"count(gene_name)_y\": \"n_ctrl_gene\"})\n",
    "    n_gene_case = sum(gene_table[\"n_case_gene\"])\n",
    "    n_gene_ctrl = sum(gene_table[\"n_ctrl_gene\"])\n",
    "    gene_table[\"n_case_nogene\"] = n_gene_case - gene_table[\"n_case_gene\"]\n",
    "    gene_table[\"n_ctrl_nogene\"] = n_gene_ctrl - gene_table[\"n_ctrl_gene\"]\n",
    "    gene_table = gene_table[[\"gene_name\", \"n_case_gene\", \"n_ctrl_gene\", \"n_case_nogene\", \"n_ctrl_nogene\"]]\n",
    "    return gene_table\n",
    "\n",
    "def get_stats(gene_table, sort = 0):\n",
    "    # from website https://pypi.python.org/pypi/fisher/\n",
    "    stats_table = [(pvalue(row[\"n_case_gene\"], row[\"n_ctrl_gene\"], row[\"n_case_nogene\"], row[\"n_ctrl_nogene\"]), row[\"gene_name\"]) \n",
    "                   for idx, row in gene_table.iterrows()]\n",
    "    p_value = [x[0].two_tail for x in stats_table]\n",
    "    oddsratio_table = [(stats.fisher_exact([[row[\"n_case_gene\"], row[\"n_ctrl_gene\"]], [row[\"n_case_nogene\"], row[\"n_ctrl_nogene\"]]])[0], row[\"gene_name\"]) \n",
    "                       for idx, row in gene_table.iterrows()]\n",
    "    if not sort == 0:\n",
    "        stats_table = sorted(stats_table, reverse=True, key = lambda x: -np.log10(x[0].two_tail))\n",
    "        oddsratio_table = sorted(oddsratio_table, reverse=True, key=lambda x: x[0] if np.isfinite(x[0]) else -x[0])\n",
    "    logp_2side = [-np.log10(x[0].two_tail) for x in stats_table]\n",
    "    logp_gene = [x[1] for x in stats_table]\n",
    "    OR_2side = [x[0] for x in oddsratio_table]\n",
    "    OR_gene = [x[1] for x in oddsratio_table]\n",
    "    stats_table = {\"p_value\": p_value, \"logp_2side\": logp_2side, \"logp_gene\": logp_gene, \"OR_2side\": OR_2side, \"OR_gene\": OR_gene}\n",
    "    return stats_table\n",
    "\n",
    "def get_stats_from_input(input_data, sort_data = 0):\n",
    "    '''input data saved from run_simulate step: sample_dup and sample_del separately'''\n",
    "    input_data = load_data(input_data)\n",
    "    sample_gene_table = get_gene_table(input_data)\n",
    "    sample_stats_table = get_stats(sample_gene_table, sort = sort_data)\n",
    "    return sample_stats_table\n",
    "\n",
    "def run_stats(input_data, output_data):\n",
    "    stats_table = get_stats_from_input(input_data, sort_data=0)\n",
    "    stats_table['debug'] = {'simulation_args': input_data['args']}\n",
    "    save_data(stats_table, output_data)\n",
    "    return stats_table\n",
    "\n",
    "def pkl_to_matrix(input_data, make_block = False, dtype = np.uint8):\n",
    "    dat = load_data(input_data)\n",
    "    ref = load_reference_gene(dat['debug']['args'][\"refgene_file\"])\n",
    "    genes = pd.Series(list(set(ref['gene_name'])))\n",
    "    regression_data = np.array([np.array(genes.isin(item[\"gene_name\"]), dtype = float) \n",
    "                                for item in dat['case'] + dat['ctrl']])\n",
    "    phenotype = np.matrix([1]*len(dat['case']) + [0]*len(dat['ctrl'])).T\n",
    "    regression_data = np.hstack((phenotype, regression_data))\n",
    "#     mask = np.ravel((regression_data==0).all(0))\n",
    "#     regression_data = np.hstack((phenotype, regression_data[:, mask]))\n",
    "    df = pd.DataFrame(regression_data, columns = ['phenotype'] + genes.tolist())\n",
    "    newdf = pd.DataFrame()\n",
    "    for col in df:\n",
    "        if sum(df[col]) > 0:\n",
    "            newdf[col] = df[col]\n",
    "        else: continue\n",
    "    if not make_block:\n",
    "        res = newdf.astype(dtype, copy = True)\n",
    "    else:\n",
    "        blocks = get_analysis_blocks(pd.concat([pd.concat(dat['case']), pd.concat(dat['ctrl'])]))\n",
    "        res = [newdf[['phenotype'] + item].astype(dtype, copy = True) for item in blocks]\n",
    "    return {\"data\": res, \"debug\": dat['debug']}\n",
    "\n",
    "\n",
    "def run_dap_lite(df, fout, grid = [(1,1),(2,2),(3,3),(4,4)], prefix = None, exec_path = None):\n",
    "    '''Convert pandas dataframe to dap input:\n",
    "        - phenotype / genotype file\n",
    "        - prior file\n",
    "        - grid file (of effect size): omega^2 + phi^2 is what we care. Let's set it to\n",
    "            1 1; 2 2; 3 3 and 4 4 for now, as we only have one Y\n",
    "    '''\n",
    "    print (str(datetime.now()))\n",
    "    import os\n",
    "    if prefix is None:\n",
    "        import time\n",
    "        prefix = \"/tmp/F\" + str(time.time())\n",
    "    if exec_path is None:\n",
    "        exec_path = 'dap/dap'\n",
    "    chrom = 'chr6'\n",
    "    pos = 100000\n",
    "    dat = [['pheno', 'trait', 'chicago'] + [str(x) for x in df['phenotype']]]\n",
    "    prior = []\n",
    "    for idx, item in enumerate(df.columns.values):\n",
    "        if item == 'phenotype':\n",
    "            continue\n",
    "        dat.append(['geno', '{}.{}'.format(chrom, pos + idx), 'chicago'] + [str(x) for x in df[item]])\n",
    "        prior.append(['{}.{}'.format(chrom, pos + idx), str(1/(df.shape[1] - 1))])\n",
    "    with open(prefix + '.dat', 'w') as f:\n",
    "        f.write('\\n'.join([' '.join(x) for x in dat]))\n",
    "    with open(prefix + '.prior', 'w') as f:\n",
    "        f.write('\\n'.join([' '.join(x) for x in prior]))\n",
    "    with open(prefix + '.grid', 'w') as f:\n",
    "        f.write('\\n'.join([' '.join(map(str, x)) for x in grid]))\n",
    "    os.system(\"{0} -d {1}.dat -g {1}.grid -t 8 -it 0.05 -prior {1}.prior > {2}\".format(exec_path, prefix, fout))\n",
    "    print (str(datetime.now()))\n",
    "#     return dat\n",
    "\n",
    "\n",
    "def run_dap(df, fileout, pthwy_genes, ref_genes, dap_method = \"dap\", grid = [(0,0.1)], multiplier = 5,  \n",
    "            exec_path = 'dap', prefix = None, dry_run = False, ncpu = 6):\n",
    "    '''Convert pandas dataframe to dap input:\n",
    "        - phenotype / genotype file\n",
    "        - prior file\n",
    "        - grid file (of effect size): omega^2 + phi^2 is what we care. Let's set it to\n",
    "          (0, beta) for now, as we only have one Y\n",
    "        dap_method: default to `dap`, other choices are `dap1`, `dap-g` (dap greedy)\n",
    "        You can experiment with multiple dap implementation using `dap_method` and `dry_run`\n",
    "        For example you set `dry_run = True`, ncpu = 3 and `dap_method = \"dap\"` \n",
    "        you'll get a line of command printed on screen that will run `dap` if you execute it in terminal.\n",
    "        Then you can change `dap_method = \"dap1\"`, run again to generate the command for `dap1` and execute\n",
    "        it in another terminal window.\n",
    "    '''\n",
    "    import time\n",
    "    times = [time.time(), None, None]\n",
    "    if prefix is None:\n",
    "        prefix = \"/tmp/F\" + str(time.time())\n",
    "    exec_path = os.path.join(exec_path or '', dap_method)\n",
    "#     chrom = [\"chr{}\".format(i) for i in list(range(1,23))+[\"X\"]]\n",
    "#     pos is all the gene names showed in .feather\n",
    "    pos = df.columns.values[1:].tolist()\n",
    "#     first item in \"dat\" is phenotype for all samples (# of rows in .feather)\n",
    "    dat = [['pheno', 'trait', 'chicago'] + [str(x) for x in df['phenotype']]]\n",
    "    prior = []\n",
    "#     item is gene namePerformance Cake PanPerformance Cake PanPerformance Cake Pan\n",
    "    for idx, item in enumerate(df.columns.values):\n",
    "        if item == \"phenotype\":\n",
    "            continue\n",
    "        dat.append(['geno', '{}.{}'.format(ref_genes[ref_genes[\"gene_name\"]==item][\"chrom\"].tolist()[0], item), \n",
    "                    'chicago'] + [str(x) for x in df[item]])\n",
    "        n_overlap_gene = len(set(pthwy_genes[\"gene_name\"]) & set(pos))\n",
    "        prior_causal = multiplier / len(set(pos))\n",
    "        div = (len(set(pos))-n_overlap_gene) or 1\n",
    "        prior_noncausal = (1-prior_causal*n_overlap_gene) / div\n",
    "        if multiplier <= 1.0:\n",
    "            prior_pr = str(1 / len(set(pos)))\n",
    "        else:\n",
    "            prior_pr = str(prior_causal) if item in pthwy_genes[\"gene_name\"].tolist() else str(prior_noncausal)\n",
    "        prior.append(['{}.{}'.format(ref_genes[ref_genes[\"gene_name\"]==item][\"chrom\"].tolist()[0], item), prior_pr])\n",
    "#     print (prior_causal, prior_noncausal)\n",
    "    with open(prefix + '.dat', 'w') as f:\n",
    "        f.write('\\n'.join([' '.join(x) for x in dat]))\n",
    "    with open(prefix + '.prior', 'w') as f:\n",
    "        f.write('\\n'.join([' '.join(x) for x in prior]))\n",
    "    with open(prefix + '.grid', 'w') as f:\n",
    "        f.write('\\n'.join([' '.join(map(str, x)) for x in grid]))\n",
    "    times[1] = time.time()\n",
    "    if dap_method == 'dap':\n",
    "        cmd = \"{0} -d {1}.dat -g {1}.grid -it 0.05 -prior {1}.prior -t {2} >> {3} \".\\\n",
    "            format(exec_path, prefix, ncpu, fileout)\n",
    "    elif dap_method == 'dap-g':\n",
    "        cmd =  \"{0} -d {1}.dat -g {1}.grid -prior {1}.prior -t {2} >> {3} \".\\\n",
    "            format(exec_path, prefix, ncpu, fileout)\n",
    "    else:\n",
    "        cmd = \"{0} -d {1}.dat -prior {1}.prior >> {2} \".\\\n",
    "            format(exec_path, prefix, fileout)\n",
    "    if not dry_run:\n",
    "        # print(cmd)\n",
    "        os.system(cmd)\n",
    "        times[2] = time.time()\n",
    "    else:\n",
    "        # generate cmd, then run under the folder of \"analysis\"\n",
    "        print(cmd)\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Power and type I error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "def get_power(stats_table, causal_genes, p = 0.05):\n",
    "    '''get power for each simulated dataset.\n",
    "    First get overlapped genes from stats table and causal genes, and find corresponding p value\n",
    "    Then power = #(p_value < 0.05) / #(p_value)'''\n",
    "    overlap_causal_genes = [gene for gene in causal_genes if gene in stats_table[\"genes\"]]\n",
    "    overlap_p_value = [stats_table[\"p_value\"][stats_table[\"genes\"].index(gene)] \n",
    "                       for gene in overlap_causal_genes]\n",
    "    pvalue_less_than_p = [x for x in overlap_p_value if x < p]\n",
    "    return len(pvalue_less_than_p)/len(overlap_causal_genes)\n",
    "\n",
    "def get_typeIerror(stats_table, causal_genes, p = 0.05):\n",
    "    '''get type I error for each simulated dataset.\n",
    "    First get the overlapped genes from noncausal genes and genes in stats table, find corresponding p value\n",
    "    Then type I error = #(p_value < 0.05) / #(p_value)\n",
    "    '''\n",
    "    noncausal_overlap_genes = [gene for gene in stats_table[\"genes\"] if gene not in causal_genes]\n",
    "    noncausal_overlap_genes_pvalue = [stats_table[\"p_value\"][stats_table[\"genes\"].index(gene)]\n",
    "                                      for gene in noncausal_overlap_genes]\n",
    "    pvalue_less_than_p = [x for x in noncausal_overlap_genes_pvalue if x < p]\n",
    "    return len(pvalue_less_than_p)/len(noncausal_overlap_genes_pvalue)\n",
    "\n",
    "def test_contingency_table(gene_table, method = \"Fisher\", option = False): \n",
    "    if (method == \"Fisher\"):\n",
    "        stats_table = [(pvalue(row[\"n_case_gene\"], row[\"n_ctrl_gene\"], row[\"n_case_nogene\"], row[\"n_ctrl_nogene\"]), \n",
    "                        row[\"gene_name\"]) for idx, row in gene_table.iterrows()]\n",
    "        p_value = [x[0].two_tail for x in stats_table]\n",
    "        genes = [x[1] for x in stats_table]\n",
    "        stats_table = {\"genes\": genes, \"p_value\": p_value}\n",
    "    else:\n",
    "        table = [( stats.chi2_contingency([[row[\"n_case_gene\"], row[\"n_ctrl_gene\"]], [row[\"n_case_nogene\"], row[\"n_ctrl_nogene\"]]], \n",
    "                                          correction = option), row[\"gene_name\"] ) \n",
    "                 for idx, row in gene_table.iterrows()]\n",
    "        p_value = [x[0][1] for x in table]\n",
    "        gene = [x[1] for x in table]\n",
    "        stats_table = {\"p_value\": p_value, \"genes\": gene}\n",
    "    return stats_table\n",
    "\n",
    "def get_power_and_typeIerror(input_data, method_option = \"chi2\", correction_option = False, p_option = 0.05):\n",
    "    '''use function \"load_data\" and \"get_gene_table\" from simulation.py, use simulated dataset as input data,\n",
    "    and get stats table by using Fisher or chisquare test.\n",
    "    Then get power and type I error by using functions above, input is stats table and causal genes'''\n",
    "    sample_table = load_data(input_data)\n",
    "    causal_genes = sample_table[\"debug\"][\"causal genes\"]\n",
    "    gene_table = get_gene_table(sample_table)\n",
    "    stats_table = test_contingency_table(gene_table, method = method_option, option = correction_option)\n",
    "    power = get_power(stats_table, causal_genes, p = p_option)\n",
    "    typeI_error = get_typeIerror(stats_table, causal_genes, p = p_option)\n",
    "    return {\"power\": power, \"typeI_error\": typeI_error, \"debug\": sample_table[\"debug\"][\"args\"]}\n",
    "\n",
    "def run_power_typeIerror(datasets):\n",
    "    '''input data must be a list of simulated datasets'''\n",
    "    res = {}\n",
    "    i = 0\n",
    "    for data in datasets:\n",
    "        res_data = get_power_and_typeIerror(data)\n",
    "        res[\"dataset_{}\".format(i)] = res_data\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Obsolete codes\n",
    "Yet may still be useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "### Simulation codes\n",
    "Here is the version using randomly sampled causal genes, and single process computation (use `ctrl` + `/` on PC or `cmd` + `/` on Mac to comment and uncomment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "kernel": "Python3"
   },
   "outputs": [],
   "source": [
    "# def p_case(p, num_causal_genes_in_sample, sim_args):\n",
    "#     if num_causal_genes_in_sample == 0:\n",
    "#         return p\n",
    "#     baseline_odds = p / (1 - p)\n",
    "#     if sim_args[\"odds_ratio_params\"][\"shape\"] is None or sim_args[\"odds_ratio_params\"][\"scale\"] is None:\n",
    "#         odds_ratio = 1\n",
    "#     else:\n",
    "#         odds_ratio = np.prod([np.random.gamma(sim_args[\"odds_ratio_params\"]['shape'], \n",
    "#                                               sim_args[\"odds_ratio_params\"]['scale']) \n",
    "#                               for x in range(num_causal_genes_in_sample)])\n",
    "#     # obtain the power of fisher test by setting odds ratio to 1\n",
    "#     # odds_ratio = 1\n",
    "#     odds = baseline_odds * odds_ratio\n",
    "#     return odds / (1 + odds)\n",
    "\n",
    "# class Environment(dict):\n",
    "#     def __init__(self):\n",
    "#         parameters = {'block_size': 100000,\n",
    "#                       'avg_cnv_per_individual': 5,\n",
    "#                       'n_case': 2000,\n",
    "#                       'n_ctrl': 2000,\n",
    "#                        # set Gamma shape to be 3 instead of 5\n",
    "#                        # 'odds_ratio_params' : None # for H_0\n",
    "#                       'odds_ratio_params': {'shape': 5, 'scale': 1},\n",
    "#                       'prevalence': 0.005,\n",
    "#                       'n_causal_gene': 200,\n",
    "#                       'refgene_file': 'data/refGene.txt.gz',\n",
    "#                       'cnv_file': 'data/ISC-r1.CNV.bed',\n",
    "#                       'case_dataset': 'delCases',\n",
    "#                       'ctrl_dataset': 'delControls',\n",
    "#                       'output': 'del_sample' \n",
    "#                      }\n",
    "#         self.update(parameters)\n",
    "#         ## select causal genes randomly, instead of the first 100 in enrichment analysis\n",
    "#         self.ref_gene_name = load_reference_gene(parameters[\"refgene_file\"])[\"gene_name\"].tolist()\n",
    "#         self.causal_genes = random.sample(self.ref_gene_name, parameters['n_causal_gene'])\n",
    "#         self.seed = 999\n",
    "\n",
    "\n",
    "# def simulate(refgene, cnv_data, args, causal_genes):\n",
    "#     df = cnv_data.drop_duplicates(subset=(\"chrom\", \"cnv_start\", \"cnv_end\"))\n",
    "#     block_counts = count_cnv_by_block(df, args['block_size'])\n",
    "#     cnv_length = cnv_data['cnv_end'] - cnv_data['cnv_start']\n",
    "#     status = 1\n",
    "#     case_data = []\n",
    "#     ctrl_data = []\n",
    "#     debug = {'p': [], 'niter': 0, 'time': [str(datetime.now()), None], 'args': dict(args), \n",
    "#              'causal genes': causal_genes, 'number of causal genes': [], 'number of genes overlap CNV': [],\n",
    "#              'simulated CNV length in case': [], 'simulated CNV length in ctrl': []}\n",
    "    \n",
    "#     while(status):\n",
    "#         sample_len = sample_cnv_length(cnv_length, args['avg_cnv_per_individual'])\n",
    "#         sample_blocks = get_sample_blocks(block_counts, len(sample_len))\n",
    "#         samples = assign_cnv_to_sample(sample_blocks, sample_len, args['block_size'])\n",
    "#         samples = annotate_samples(samples, refgene)\n",
    "#         causal_genes_in_sample = get_causal_genes(causal_genes, samples['gene_name'].tolist())\n",
    "#         p = p_case(args['prevalence'], len(causal_genes_in_sample), args)\n",
    "#         # add the number of causal genes overlapped with simulated CNVs for each simulated sample\n",
    "#         debug['number of causal genes'].append(len(causal_genes_in_sample))\n",
    "#         # add the number of genes overlapped with simulated CNVs, both causal and non-causal genes\n",
    "#         debug['number of genes overlap CNV'].append(len( set(samples['gene_name'].tolist()) ))\n",
    "#         #debug['p'].append(p)\n",
    "#         if random.random() < p and len(case_data) < args['n_case']:\n",
    "#             # sample data is a case\n",
    "#             case_data.append(samples)\n",
    "#             debug['p'].append(p)\n",
    "#             debug['simulated CNV length in case'].extend(sample_len)\n",
    "#         if random.random() > p and len(ctrl_data) < args['n_ctrl']:\n",
    "#             # sample data is a control\n",
    "#             ctrl_data.append(samples)\n",
    "#             debug['p'].append(p)\n",
    "#             debug['simulated CNV length in ctrl'].extend(sample_len)\n",
    "#         if len(case_data) == args['n_case'] and len(ctrl_data) == args['n_ctrl']:\n",
    "#             status = 0\n",
    "#         debug['niter'] += 1\n",
    "#     debug['time'][1] = str(datetime.now())\n",
    "#     return {'case': case_data, 'ctrl': ctrl_data, 'debug': debug}\n",
    "\n",
    "# def save_data(data, filename):\n",
    "#     pickle.dump(data, open(filename, \"wb\"))\n",
    "\n",
    "# def load_data(filename):\n",
    "#     return pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "\n",
    "# def run_simulation(args, simulation_id = 0):\n",
    "#     np.random.seed(args.seed)\n",
    "#     ref_gene = load_reference_gene(args['refgene_file'])\n",
    "#     cnv_data = load_cnv_data(args['cnv_file'])\n",
    "#     sample_data = simulate(ref_gene, pd.concat([cnv_data[args['case_dataset']], cnv_data[args['ctrl_dataset']]]),\n",
    "#                           args, args.causal_genes)\n",
    "#     save_data(sample_data, '{}_{}.data.pkl'.format(args['output'], simulation_id))\n",
    "#     return sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Python3"
   },
   "source": [
    "## Export all to module `utils.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "Python3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from Python_Utils.ipynb\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python extract_function.py --from Python_Utils.ipynb --to ../analysis/utils.py ../prototype/utils.py utils.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "default_kernel": "Python3",
   "kernels": [
    [
     "Python3",
     "python3",
     "Python3",
     "#FFE771"
    ]
   ],
   "panel": {
    "displayed": false,
    "height": 0,
    "style": "side"
   },
   "version": "0.9.15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
